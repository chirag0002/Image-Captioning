from gradio import Interface, Image, Textbox
from transformers import AutoProcessor, AutoModelForCausalLM
import torch


device = "cuda" if torch.cuda.is_available() else "cpu"

git_processor_large_coco = AutoProcessor.from_pretrained("microsoft/git-large-coco")
git_model_large_coco = AutoModelForCausalLM.from_pretrained("microsoft/git-large-coco").to(device)

def generate_caption(processor, model, image, use_float_16=False):
    inputs = processor(images=image, return_tensors="pt").to(device)

    if use_float_16:
        inputs = inputs.to(torch.float16)
    
    generated_ids = model.generate(pixel_values=inputs.pixel_values, num_beams=3, max_length=20, min_length=5) 

    generated_caption = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
   
    return generated_caption


def generate_captions(image):
    captions = generate_caption(git_processor_large_coco, git_model_large_coco, image)
    print(f"Caption generated: {captions}")
    return captions

outputs = [Textbox(label="Caption generated by GIT-large fine-tuned on COCO")]

inputs = Image(type="pil")

title = "image captioning Model"

interface = Interface(fn=generate_captions,
                      inputs=inputs,
                      outputs=outputs,
                      title=title)
interface.launch(share=True)